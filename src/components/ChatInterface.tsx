'use client';

import { useState, useEffect, useRef } from 'react';
import { speechToText, generateResponse, textToSpeech, ChatMessage } from '@/services/ai';
import { getVoiceProfileByRole } from '@/services/voice';

export default function ChatInterface() {
    const [messages, setMessages] = useState<ChatMessage[]>([]);
    const [isListening, setIsListening] = useState(false);
    const [isProcessing, setIsProcessing] = useState(false);
    const [isPlaying, setIsPlaying] = useState(false);
    const [hasVoiceRegistered, setHasVoiceRegistered] = useState(false);
    
    const mediaRecorderRef = useRef<MediaRecorder | null>(null);
    const audioChunksRef = useRef<Blob[]>([]);
    const currentAudioRef = useRef<HTMLAudioElement | null>(null);

    // Auto-scroll to bottom
    const messagesEndRef = useRef<HTMLDivElement>(null);
    const scrollToBottom = () => {
        messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
    };
    useEffect(scrollToBottom, [messages]);

    // Check if voice is registered on mount
    useEffect(() => {
        const childVoice = getVoiceProfileByRole('child');
        setHasVoiceRegistered(!!childVoice?.voiceModelId);
    }, []);

    const handleStartListening = async () => {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorderRef.current = new MediaRecorder(stream);
            audioChunksRef.current = [];

            mediaRecorderRef.current.ondataavailable = (e) => {
                if (e.data.size > 0) {
                    audioChunksRef.current.push(e.data);
                }
            };

            mediaRecorderRef.current.onstop = async () => {
                const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
                await handleProcessing(audioBlob);
                // Stop all tracks to release microphone
                stream.getTracks().forEach(track => track.stop());
            };

            mediaRecorderRef.current.start();
            setIsListening(true);
        } catch (err) {
            console.error('Error accessing microphone:', err);
            alert('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
        }
    };

    const handleStopListening = () => {
        if (mediaRecorderRef.current && isListening) {
            mediaRecorderRef.current.stop();
            setIsListening(false);
        }
    };

    const handleProcessing = async (audioBlob: Blob) => {
        setIsProcessing(true);

        try {
            // 1. STT: Convert audio to text
            const userText = await speechToText(audioBlob);
            if (!userText || userText.trim() === '') {
                alert('ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§í•´ì£¼ì„¸ìš”.');
                setIsProcessing(false);
                return;
            }

            const userMsg: ChatMessage = { role: 'user', text: userText };
            setMessages(prev => [...prev, userMsg]);

            // 2. LLM: Generate response
            const aiText = await generateResponse(userText);

            // 3. TTS: Convert response to audio using child's voice
            const audioUrl = await textToSpeech(aiText, 'child');

            const aiMsg: ChatMessage = { role: 'assistant', text: aiText, audioUrl };
            setMessages(prev => [...prev, aiMsg]);

            // 4. Auto-play the audio response
            if (audioUrl) {
                await playAudio(audioUrl);
            }

        } catch (error) {
            console.error("Conversation error:", error);
            alert("ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: " + (error as Error).message);
        } finally {
            setIsProcessing(false);
        }
    };

    const playAudio = (audioUrl: string): Promise<void> => {
        return new Promise((resolve, reject) => {
            // Stop any currently playing audio
            if (currentAudioRef.current) {
                currentAudioRef.current.pause();
                currentAudioRef.current = null;
            }

            setIsPlaying(true);
            const audio = new Audio(audioUrl);
            currentAudioRef.current = audio;

            audio.onended = () => {
                setIsPlaying(false);
                currentAudioRef.current = null;
                // Clean up the object URL
                URL.revokeObjectURL(audioUrl);
                resolve();
            };

            audio.onerror = (error) => {
                setIsPlaying(false);
                currentAudioRef.current = null;
                URL.revokeObjectURL(audioUrl);
                reject(error);
            };

            audio.play().catch(reject);
        });
    };

    return (
        <div style={{ display: 'flex', flexDirection: 'column', height: 'calc(100vh - 100px)' }}>
            {/* Chat History */}
            <div style={{ flex: 1, overflowY: 'auto', padding: '16px', display: 'flex', flexDirection: 'column', gap: '16px' }}>
                {messages.length === 0 && (
                    <div style={{ textAlign: 'center', marginTop: '40px', color: '#888' }}>
                        {!hasVoiceRegistered ? (
                            <>
                                <p style={{ fontSize: '24px', marginBottom: '16px' }}>
                                    ìë…€ì˜ ëª©ì†Œë¦¬ê°€ ë“±ë¡ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.
                                </p>
                                <p style={{ fontSize: '18px' }}>
                                    ë¨¼ì € ëª©ì†Œë¦¬ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.
                                </p>
                            </>
                        ) : (
                            <p style={{ fontSize: '24px' }}>
                                ëŒ€í™” ì‹œì‘í•˜ê¸° ë²„íŠ¼ì„ ëˆŒëŸ¬<br />ì´ì•¼ê¸°ë¥¼ ì‹œì‘í•´ë³´ì„¸ìš”.
                            </p>
                        )}
                    </div>
                )}

                {messages.map((msg, idx) => (
                    <div key={idx} style={{
                        alignSelf: msg.role === 'user' ? 'flex-end' : 'flex-start',
                        maxWidth: '80%',
                        backgroundColor: msg.role === 'user' ? '#E8F5E9' : '#F5F5F5',
                        padding: '16px',
                        borderRadius: '16px',
                        borderBottomRightRadius: msg.role === 'user' ? '4px' : '16px',
                        borderBottomLeftRadius: msg.role === 'assistant' ? '4px' : '16px',
                        fontSize: '20px'
                    }}>
                        <div style={{ fontWeight: 'bold', marginBottom: '4px', fontSize: '14px', color: '#666' }}>
                            {msg.role === 'user' ? 'ë‚˜' : 'ìë…€'}
                        </div>
                        {msg.text}
                    </div>
                ))}

                {isProcessing && (
                    <div style={{ alignSelf: 'flex-start', padding: '16px', backgroundColor: '#F5F5F5', borderRadius: '16px' }}>
                        ìƒê°í•˜ëŠ” ì¤‘... ğŸ¤”
                    </div>
                )}
                <div ref={messagesEndRef} />
            </div>

            {/* Controls */}
            <div style={{ padding: '16px', borderTop: '1px solid #eee', backgroundColor: 'white' }}>
                {isPlaying ? (
                    <button className="btn-large btn-accent" disabled>
                        ğŸ”Š ë§í•˜ëŠ” ì¤‘...
                    </button>
                ) : isListening ? (
                    <button onClick={handleStopListening} className="btn-large btn-accent" style={{ animation: 'pulse 1s infinite' }}>
                        ğŸ‘‚ ë“£ê³  ìˆì–´ìš”... (ëˆ„ë¥´ë©´ ì¤‘ì§€)
                    </button>
                ) : (
                    <button 
                        onClick={handleStartListening} 
                        className="btn-large" 
                        disabled={isProcessing || !hasVoiceRegistered}
                    >
                        {!hasVoiceRegistered 
                            ? 'ë¨¼ì € ëª©ì†Œë¦¬ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”' 
                            : isProcessing 
                                ? 'ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”' 
                                : 'ğŸ—£ï¸ ëŒ€í™” ì‹œì‘í•˜ê¸°'
                        }
                    </button>
                )}
            </div>

            <style jsx>{`
        @keyframes pulse {
          0% { opacity: 1; transform: scale(1); }
          50% { opacity: 0.8; transform: scale(0.98); }
          100% { opacity: 1; transform: scale(1); }
        }
      `}</style>
        </div>
    );
}
